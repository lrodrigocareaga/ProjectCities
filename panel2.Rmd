---
title: "Regression 2"
author: "Ana Real and Rodrigo Careaga"
date: "March 26, 2019"
output: 
  html_document:
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Getting the regression.

For this experiment we are going to use the median of the student_view variable from years 2017 and 2018 for the rest of the years and adding it to the final score.

### Loading the data

```{r load, cache=TRUE}
library(xlsx)

data <- read.xlsx2("./cityData.xlsx", sheetIndex = 1)
for (i in 3:9){
    data[,i] <- as.numeric(as.character(data[,i]))
}


```

### Working with some missing values

```{r nas, cache=TRUE}
# Hong Kong 2014 had a NA for ranking, we get that value by calculating the difference between the overall and the rest of the variables.
data[333,"rankings"] <- data[333,"overall"]-sum(data[333,c(5:9)])

# Same for Chicago

data[349,"rankings"] <- data[349,"overall"]-sum(data[349,c(5:9)])

# For Philadelphia we just know the overall, to get the values of the rest of the variables we are extracting the values of the rest of the United States' cities and get an average percentage for each variable and multiplied to get the overall we know.

UScities <- data[(data$city=="Boston"|data$city=="San Francisco"|data$city=="New York"|data$city=="Washington DC"|data$city=="Los Angeles"|data$city=="Chicago")&data$year==2014,c(3:9)]

perc <- apply(UScities,1,function(x){x[2:7]/x[1]})
num <- apply(perc,1,mean)
data[370,c(4:9)] <- data[370,3]*num

# Kyoto in 2014
data[376,6] <- data[376,"overall"]-sum(data[376,c(4,5,7,8)])

for (j in 4:9){
    for (i in 1:376){
        data[i,j] <- ceiling(data[i,j])
    }
}

str(data)
```

### Calculating the median from student view and pasting it to a final data set.

```{r data, cache=TRUE}

student <- data[data$year=="2018",c("city","student_view")]
student1 <- data[data$year=="2017",c("city","student_view")]
for (j in 1:length(student$city)){
    for(i in 1:length(student1$city)){
        if(student$city[j]==student1$city[i]){
            student$student_view[j] <- ceiling(median(student$student_view[j]:student1$student_view[i]))
        }
    }
}

for (i in 202:376){
    for (j in 1:101){
        if(student$city[j]==data$city[i]){
            data$student_view[i] <- student$student_view[j]
        }
    }
}

for (i in 1:376){
    data$overall[i] <- sum(data[i,4:9], na.rm = TRUE)
}

summary(data)
```

### Exporting data frame.

```{r export, cache=TRUE}
write.xlsx2(data, "city.xlsx", sheetName = "panel", row.names = FALSE)
```

### New linear regression.

```{r fit, fig.height=8, fig.width=8}
library(knitr)
str(data)
sum(is.na(data))
data$city <- as.factor(data$city)
data1 <- data[data$year!=2018,]
fit <- lm(overall~rankings+student_view+desirability+emp_activity+affordability+student_view+city, data=data1)
summary(fit)

# Diagnostic of residuals.
par(mfrow=c(2,2))
plot(fit)

# Prediction
test <- data[data$year==2018,]

# Removing some cities that did not appear before 2018 and the model cannot predict
data2 <- test[-grep("Aberdeen",test$city),]
data2 <- data2[-grep("Brighton",data2$city),]
data2 <- data2[-grep("Cape Town",data2$city),]
data2 <- data2[-grep("Dubai-Sharjah-Ajman",data2$city),]
data2 <- data2[-grep("Graz",data2$city),]
data2 <- data2[-grep("Miami",data2$city),]
data2 <- data2[-grep("Nagoya",data2$city),]
data2 <- data2[-grep("Stuttgart",data2$city),]
result <- predict(fit, data2)
error <- paste(abs(result-data2[,"overall"])/data2[,"overall"]*100,"%")
set <- cbind(as.character(data2[,"city"]),data2[,"overall"],result,error)
colnames(set) <- c("City", "Test", "Predicted", "Error")
summary(abs(result-data2[,"overall"])/data2[,"overall"]*100)
kable(set)
```

